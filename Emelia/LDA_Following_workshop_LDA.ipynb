{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a78986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fd77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c638d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5b61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33a5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://drive.google.com/file/d/1si7B_mq8EnoUNFjBEovILwPfzYW8Gjn8/view'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "trainingDf = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c365e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45921218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lmtzr = nltk.WordNetLemmatizer().lemmatize\n",
    "\n",
    "## We lookup whether a word is and adjective, verb, noun or adverb here.\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "    \n",
    "## This version uses word type. Needs the bigger nltp download (\"popular\")\n",
    "def normalize_text(text):\n",
    "    ## Runs on documents (vector of words)\n",
    "    word_pos = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    lemm_words = [lmtzr(sw[0], get_wordnet_pos(sw[1])) for sw in word_pos]\n",
    "\n",
    "    return [x.lower() for x in lemm_words]\n",
    "\n",
    "##Â This version doesn't require the \"popular\" download\n",
    "def preprocess(text):\n",
    "    ## Runs on documents (vector of words)\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    return([lemmatizer.lemmatize(i) for i in text.split()])\n",
    "\n",
    "################\n",
    "## wordnet version\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    ## morphy does a lemma lookup and word standardization\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "## lemmatize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "## This version is for comparison\n",
    "def prepare_text_for_lda(text):\n",
    "    ## Runs on documents (vector of words)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f52059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [good, and, helpfull, read, this, book, is, ve...\n",
       "1    [Sadly, overpriced, and, irrelevant, In, spite...\n",
       "2    [Endless, rant, Howard, should, have, borrowed...\n",
       "3    [Not, Quite, Hip, It's, really, a, shame, abou...\n",
       "4    [Journey, to, the, Centre, of, the, Earth, Hey...\n",
       "5    [No, longer, the, Land, of, the, Free, The, re...\n",
       "6    [DEMON, IN, MY, VIEW-AMELIA, ATWATER-RHODES, A...\n",
       "7    [Heartbreaking...but, you'll, live, The, novel...\n",
       "8    [I, waited, for, this?, I, got, this, book, wh...\n",
       "9    [Awesome!, The, book, wa, absolutely, beautifu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = trainingDf['text'].map(preprocess) # preprocess is faster than normalise_text.\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f646bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1702b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f485dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0edf2a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating corpus and saving to pickle\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating corpus and saving to pickle\")\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "pickle.dump(bow_corpus, open('bow_corpusE.pkl', 'wb'))\n",
    "pickle.dump(dictionary, open('dictionaryE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62203424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 2 (\"but\") appears 3 time.\n",
      "Word 17 (\"more\") appears 1 time.\n",
      "Word 20 (\"really\") appears 1 time.\n",
      "Word 22 (\"some\") appears 1 time.\n",
      "Word 26 (\"there\") appears 1 time.\n",
      "Word 30 (\"very\") appears 1 time.\n",
      "Word 42 (\"The\") appears 3 time.\n",
      "Word 47 (\"about\") appears 1 time.\n",
      "Word 55 (\"all\") appears 2 time.\n",
      "Word 62 (\"at\") appears 3 time.\n",
      "Word 72 (\"completely\") appears 1 time.\n",
      "Word 83 (\"do\") appears 1 time.\n",
      "Word 102 (\"half\") appears 2 time.\n",
      "Word 103 (\"have\") appears 3 time.\n",
      "Word 123 (\"no\") appears 1 time.\n",
      "Word 124 (\"none\") appears 1 time.\n",
      "Word 125 (\"not\") appears 1 time.\n",
      "Word 127 (\"on\") appears 2 time.\n",
      "Word 128 (\"one\") appears 1 time.\n",
      "Word 129 (\"or\") appears 1 time.\n",
      "Word 149 (\"so\") appears 1 time.\n",
      "Word 158 (\"time\") appears 1 time.\n",
      "Word 168 (\"where\") appears 1 time.\n",
      "Word 170 (\"which\") appears 1 time.\n",
      "Word 171 (\"with\") appears 3 time.\n",
      "Word 190 (\"don't\") appears 1 time.\n",
      "Word 195 (\"from\") appears 1 time.\n",
      "Word 198 (\"his\") appears 1 time.\n",
      "Word 250 (\"he\") appears 2 time.\n",
      "Word 253 (\"him\") appears 1 time.\n",
      "Word 259 (\"like\") appears 1 time.\n",
      "Word 261 (\"must\") appears 1 time.\n",
      "Word 326 (\"end\") appears 1 time.\n",
      "Word 359 (\"first\") appears 1 time.\n",
      "Word 363 (\"liked\") appears 1 time.\n",
      "Word 387 (\"different\") appears 1 time.\n",
      "Word 411 (\"plot\") appears 1 time.\n",
      "Word 450 (\"after\") appears 1 time.\n",
      "Word 460 (\"even\") appears 1 time.\n",
      "Word 529 (\"I'm\") appears 1 time.\n",
      "Word 538 (\"any\") appears 1 time.\n",
      "Word 560 (\"especially\") appears 1 time.\n",
      "Word 572 (\"himself,\") appears 1 time.\n",
      "Word 662 (\"move\") appears 2 time.\n",
      "Word 711 (\"least\") appears 1 time.\n",
      "Word 724 (\"stuff\") appears 1 time.\n",
      "Word 779 (\"part\") appears 1 time.\n",
      "Word 858 (\"novel.\") appears 1 time.\n",
      "Word 867 (\"something\") appears 1 time.\n",
      "Word 905 (\"And\") appears 1 time.\n",
      "Word 951 (\"difference\") appears 1 time.\n",
      "Word 955 (\"editor\") appears 1 time.\n",
      "Word 1174 (\"over\") appears 1 time.\n",
      "Word 1197 (\"religion\") appears 1 time.\n",
      "Word 1201 (\"second\") appears 1 time.\n",
      "Word 1408 (\"everyone\") appears 1 time.\n",
      "Word 1554 (\"connect\") appears 1 time.\n",
      "Word 1556 (\"fiction,\") appears 1 time.\n",
      "Word 1666 (\"brings\") appears 1 time.\n",
      "Word 1777 (\"including\") appears 1 time.\n",
      "Word 1926 (\"pretty\") appears 1 time.\n",
      "Word 2376 (\"crime\") appears 1 time.\n",
      "Word 2456 (\"there's\") appears 1 time.\n",
      "Word 2519 (\"enjoyed\") appears 1 time.\n",
      "Word 2681 (\"connecting\") appears 1 time.\n",
      "Word 2861 (\"plot,\") appears 1 time.\n",
      "Word 3127 (\"to.\") appears 1 time.\n",
      "Word 3199 (\"mystery,\") appears 1 time.\n",
      "Word 3795 (\"proverbial\") appears 1 time.\n",
      "Word 3896 (\"spends\") appears 1 time.\n",
      "Word 4054 (\"something.\") appears 1 time.\n",
      "Word 4256 (\"comparison\") appears 1 time.\n",
      "Word 4950 (\"2000.\") appears 1 time.\n",
      "Word 5246 (\"willing\") appears 1 time.\n",
      "Word 6270 (\"apt\") appears 1 time.\n",
      "Word 7846 (\"whereas\") appears 1 time.\n",
      "Word 7990 (\"switched\") appears 1 time.\n",
      "Word 8387 (\"formulaic\") appears 1 time.\n",
      "Word 8749 (\"problem,\") appears 1 time.\n",
      "Word 9027 (\"truck\") appears 1 time.\n",
      "Word 9125 (\"River,\") appears 1 time.\n",
      "Word 9702 (\"Carl\") appears 1 time.\n",
      "Word 10187 (\"ran\") appears 1 time.\n",
      "Word 12355 (\"Raymond\") appears 1 time.\n",
      "Word 12356 (\"cult\") appears 2 time.\n",
      "Word 12357 (\"general,\") appears 1 time.\n",
      "Word 12358 (\"relevant,\") appears 1 time.\n",
      "Word 12359 (\"solution,\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_16 = bow_corpus[1000]\n",
    "\n",
    "for i in range(len(bow_doc_16)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_16[i][0], \n",
    "                                               dictionary[bow_doc_16[i][0]], \n",
    "                                                bow_doc_16[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e93515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.13680446895709966),\n",
      " (1, 0.22357034541838006),\n",
      " (2, 0.08448633111521395),\n",
      " (3, 0.22272383387233372),\n",
      " (4, 0.19479764099028732),\n",
      " (5, 0.15505766682846991),\n",
      " (6, 0.17140018835933787),\n",
      " (7, 0.20706215084319432),\n",
      " (8, 0.24790150235920178),\n",
      " (9, 0.10957731696404206),\n",
      " (10, 0.11037529753101362),\n",
      " (11, 0.1600336402015205),\n",
      " (12, 0.19817624508922924),\n",
      " (13, 0.33165340348502614),\n",
      " (14, 0.16077018290616207),\n",
      " (15, 0.0818448203705459),\n",
      " (16, 0.17623034848572441),\n",
      " (17, 0.06797125117132176),\n",
      " (18, 0.3415960748877919),\n",
      " (19, 0.044529894508430846),\n",
      " (20, 0.08993478504754539),\n",
      " (21, 0.11069440822829753),\n",
      " (22, 0.08025360783600693),\n",
      " (23, 0.2816137209010218),\n",
      " (24, 0.08484649134817178),\n",
      " (25, 0.29045998608754864),\n",
      " (26, 0.09195865510941037),\n",
      " (27, 0.08045096618131507),\n",
      " (28, 0.09819980195139141),\n",
      " (29, 0.18223808169998368),\n",
      " (30, 0.06891912002600492),\n",
      " (31, 0.07195495996050973),\n",
      " (32, 0.0715940762794895),\n",
      " (33, 0.1496925070573312)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0d8c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lda_model and saving to pickle\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lda_model=pickle.load(open('lda_modelE.pkl', 'rb'))\n",
    "    print(\"Reading lda_model from pickle\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Creating lda_model and saving to pickle\")\n",
    "    lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "    pickle.dump(lda_model,open('lda_modelE.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ccc5947",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis.gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23368\\3425614639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Visualisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis.gensim'"
     ]
    }
   ],
   "source": [
    "#Visualisation\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7a8a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\ego99\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.0.post1)\n",
      "Requirement already satisfied: future in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: funcy in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.18)\n",
      "Requirement already satisfied: numexpr in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.21.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (63.4.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ego99\\anaconda3\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ego99\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ego99\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ego99\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ego99\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ego99\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ego99\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3809ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
