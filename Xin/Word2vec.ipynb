{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba8d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import joblib\n",
    "import pickle\n",
    "import time\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78683673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size=1000\n",
    "#The number of dimensions of embeddings, the default is 100\n",
    "window=3\n",
    "#The maximum distance between a target word and its neighbours, default is 5\n",
    "min_count=3\n",
    "#The minimum counts of words in order for the word to be considered for the training of model, default is 5\n",
    "workers=3\n",
    "#The number of partitions during training, default is 3\n",
    "sg=1\n",
    "#The training algorithom, either CBOW(0) or skip gram(1), default is CBOW\n",
    "\n",
    "#train model on the training data set\n",
    "start_t = time.time()\n",
    "#tokens = pd.Series(df['tokenized_text']).values\n",
    "w2vmodel=Word2Vec(df['text'],min_count=min_count,vector_size=vector_size,workers=workers,sg=sg)\n",
    "print('Time taken to train word2vec model:' +str(time.time()-start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28def5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='w2v_model.joblib'\n",
    "joblib.dump(w2vmodel,filename)\n",
    "#save model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d6a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model=joblib.load('w2v_model.joblib')\n",
    "#load model from the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b5a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://builtin.com/machine-learning/nlp-word2vec-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0621eb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\": 0,\n",
       " ' ': 1,\n",
       " ',': 2,\n",
       " 'e': 3,\n",
       " 'o': 4,\n",
       " 't': 5,\n",
       " 'a': 6,\n",
       " 'r': 7,\n",
       " 'i': 8,\n",
       " 'n': 9,\n",
       " 'l': 10,\n",
       " 's': 11,\n",
       " 'c': 12,\n",
       " 'd': 13,\n",
       " 'u': 14,\n",
       " 'h': 15,\n",
       " 'm': 16,\n",
       " 'p': 17,\n",
       " 'y': 18,\n",
       " 'g': 19,\n",
       " 'b': 20,\n",
       " 'f': 21,\n",
       " 'w': 22,\n",
       " 'k': 23,\n",
       " 'v': 24,\n",
       " 'x': 25,\n",
       " 'j': 26,\n",
       " 'q': 27,\n",
       " '[': 28,\n",
       " ']': 29,\n",
       " 'z': 30,\n",
       " '\\\\': 31,\n",
       " '0': 32,\n",
       " '5': 33,\n",
       " '3': 34}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ab568ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 1000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>0.054114</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>-0.033160</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>-0.008433</td>\n",
       "      <td>-0.007477</td>\n",
       "      <td>-0.006783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039157</td>\n",
       "      <td>-0.005062</td>\n",
       "      <td>0.037347</td>\n",
       "      <td>0.093640</td>\n",
       "      <td>-0.008174</td>\n",
       "      <td>-0.141246</td>\n",
       "      <td>0.071199</td>\n",
       "      <td>-0.060362</td>\n",
       "      <td>-0.135622</td>\n",
       "      <td>0.016340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.127460</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.074181</td>\n",
       "      <td>0.051492</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>-0.066379</td>\n",
       "      <td>-0.060445</td>\n",
       "      <td>-0.008813</td>\n",
       "      <td>-0.040423</td>\n",
       "      <td>-0.087535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006411</td>\n",
       "      <td>-0.007434</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.081120</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>-0.102746</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>-0.020782</td>\n",
       "      <td>-0.007014</td>\n",
       "      <td>0.019138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.003650</td>\n",
       "      <td>0.021568</td>\n",
       "      <td>0.029770</td>\n",
       "      <td>-0.016037</td>\n",
       "      <td>-0.015945</td>\n",
       "      <td>-0.050476</td>\n",
       "      <td>-0.028253</td>\n",
       "      <td>0.015796</td>\n",
       "      <td>-0.027874</td>\n",
       "      <td>-0.085676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044416</td>\n",
       "      <td>-0.036430</td>\n",
       "      <td>0.076661</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>0.061231</td>\n",
       "      <td>-0.040119</td>\n",
       "      <td>-0.091887</td>\n",
       "      <td>0.008445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.141973</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.093266</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>0.105639</td>\n",
       "      <td>-0.085066</td>\n",
       "      <td>-0.074506</td>\n",
       "      <td>-0.039917</td>\n",
       "      <td>-0.020782</td>\n",
       "      <td>-0.073893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>-0.009332</td>\n",
       "      <td>0.038154</td>\n",
       "      <td>0.059182</td>\n",
       "      <td>-0.026947</td>\n",
       "      <td>-0.116407</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>-0.058576</td>\n",
       "      <td>-0.007673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.078635</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.058469</td>\n",
       "      <td>-0.005100</td>\n",
       "      <td>0.071139</td>\n",
       "      <td>-0.070614</td>\n",
       "      <td>-0.042454</td>\n",
       "      <td>-0.006450</td>\n",
       "      <td>-0.033772</td>\n",
       "      <td>-0.078628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049594</td>\n",
       "      <td>-0.011734</td>\n",
       "      <td>0.041759</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>-0.035084</td>\n",
       "      <td>-0.067613</td>\n",
       "      <td>0.072490</td>\n",
       "      <td>-0.059403</td>\n",
       "      <td>-0.119693</td>\n",
       "      <td>-0.001453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "'  0.054114  0.009230  0.048426  0.003666  0.042586 -0.033160 -0.018812   \n",
       "   0.127460  0.008905  0.074181  0.051492  0.046131 -0.066379 -0.060445   \n",
       ", -0.003650  0.021568  0.029770 -0.016037 -0.015945 -0.050476 -0.028253   \n",
       "e  0.141973  0.012968  0.093266  0.037688  0.105639 -0.085066 -0.074506   \n",
       "o  0.078635  0.034861  0.058469 -0.005100  0.071139 -0.070614 -0.042454   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "' -0.008433 -0.007477 -0.006783  ...  0.039157 -0.005062  0.037347  0.093640   \n",
       "  -0.008813 -0.040423 -0.087535  ... -0.006411 -0.007434  0.016875  0.081120   \n",
       ",  0.015796 -0.027874 -0.085676  ...  0.044416 -0.036430  0.076661  0.057377   \n",
       "e -0.039917 -0.020782 -0.073893  ...  0.013676 -0.009332  0.038154  0.059182   \n",
       "o -0.006450 -0.033772 -0.078628  ...  0.049594 -0.011734  0.041759  0.026871   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "' -0.008174 -0.141246  0.071199 -0.060362 -0.135622  0.016340  \n",
       "   0.002024 -0.102746  0.031919 -0.020782 -0.007014  0.019138  \n",
       ",  0.008156  0.033917  0.061231 -0.040119 -0.091887  0.008445  \n",
       "e -0.026947 -0.116407  0.042542 -0.027317 -0.058576 -0.007673  \n",
       "o -0.035084 -0.067613  0.072490 -0.059403 -0.119693 -0.001453  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://towardsdatascience.com/word2vec-explained-49c52b4ccb71\n",
    "\n",
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [w2vmodel.wv.get_vector(str(n)) for n in w2vmodel.wv.key_to_index],\n",
    "        index = w2vmodel.wv.key_to_index\n",
    "    )\n",
    ")\n",
    "print(emb_df.shape)\n",
    "\n",
    "emb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652fad4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'wonderful' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0s/xfpwvv6x0fg3pkqm99zxr6z40000gq/T/ipykernel_85329/4150526841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2vmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wonderful'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0mall_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'wonderful' not present\""
     ]
    }
   ],
   "source": [
    "print(w2vmodel.wv.most_similar('wonderful'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "               \"and 'wonderland' - Skip Gram : \",\n",
    "    model1.wv.similarity('alice', 'wonderland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1b955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(['sadly', 'overprice', 'irrelevant', 'spite', 'claim', 'illustrate', 'pmo', 'effective', 'reducing', 'cost', 'project', 'decrease', 'time', 'market', 'new', 'product', 'increase', 'corporate', 'profit', 'ensure', 'project', 'success', 'small', 'overprice', 'book', 'actually', 'none', 'thingsa', 'collection', 'unrelated', 'article', 'write', 'dry', 'overly', 'academic', 'style', 'book', 'totally', 'fail', 'address', 'proposition', 'project', 'management', 'office', 'pmo', 'add', 'value', 'organization', 'many', 'statement', 'effect', 'the', 'pmo', 'perform', 'function', 'assertion', 'function', 'itself', 'whether', 'easily', 'perform', 'organization', 'not', 'formal', 'pmoit', 'surprise', 'half', 'eight', 'chapter', 'relationship', 'pmo', 'function', 'all', 'discuss', 'various', 'project', 'management', 'issue', 'interest', 'well', 'cover', 'elsewhere', 'literature', 'topic', 'not', 'one', 'expect', 'purchase', 'book', 'purportedly', 'discuss', 'pmo', 'functionthe', 'book', 'completely', 'devoid', 'real', 'world', 'examples', 'leave', 'author', 'assertion', 'efficacy', 'idea', 'also', 'paucity', 'real', 'action', 'item', 'chapter', 'implement', 'pmo', 'ob', 'group', 'report', 'organization', 'practical', 'stepbystep', 'advice', 'actually', 'create', 'pmo', 'chapter', 'do', 'however', 'contain', 'interesting', 'albeit', 'irrelevant', 'discussion', 'manage', 'project', 'virtual', 'teamsas', 'someone', 'charge', 'actually', 'create', 'work', 'pmo', 'large', 'organization', 'extremely', 'disappointed', 'book', 'offer', 'almost', 'practical', 'information', 'topic'], [1])\n"
     ]
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['text'])]\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9b6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "doc2vec_model = Doc2Vec(documents, vector_size=1000, window=3, min_count=1, workers=4)\n",
    "print('Time taken to train word2vec model:' +str(time.time()-start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47c36f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d2v_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='d2v_model.joblib'\n",
    "joblib.dump(doc2vec_model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c88c3516",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter doc_words of infer_vector() must be a list of strings (not a single string).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0s/xfpwvv6x0fg3pkqm99zxr6z40000gq/T/ipykernel_85329/1972154742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top 10 values in Doc2Vec inferred vector:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36minfer_vector\u001b[0;34m(self, doc_words, alpha, min_alpha, epochs)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \"\"\"\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a common mistake; fail with a nicer error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameter doc_words of infer_vector() must be a list of strings (not a single string).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameter doc_words of infer_vector() must be a list of strings (not a single string)."
     ]
    }
   ],
   "source": [
    "vector = doc2vec_model.infer_vector(df['text'][0])\n",
    "print(len(vector))\n",
    "print(\"Top 10 values in Doc2Vec inferred vector:\")\n",
    "print(vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a6e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
